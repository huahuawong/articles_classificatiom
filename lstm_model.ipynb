{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcba625",
   "metadata": {},
   "source": [
    "## 1. Getting all the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd8dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPool1D, Embedding, Input\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import itertools\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 5000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7784b18",
   "metadata": {},
   "source": [
    "## 2. Loading data\n",
    "\n",
    "Read the data that was stored in the JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd48dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\\arxiv-metadata-oai-snapshot.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[[Bal√°zs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>23 pages, 3 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>None</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2008-01-13</td>\n",
       "      <td>[[Pan, Hongjun, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>11 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>None</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[[Callan, David, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>Alberto Torchinsky</td>\n",
       "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>None</td>\n",
       "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "      <td>None</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2013-10-15</td>\n",
       "      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           submitter  \\\n",
       "0  0704.0001      Pavel Nadolsky   \n",
       "1  0704.0002        Louis Theran   \n",
       "2  0704.0003         Hongjun Pan   \n",
       "3  0704.0004        David Callan   \n",
       "4  0704.0005  Alberto Torchinsky   \n",
       "\n",
       "                                             authors  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                    Ileana Streinu and Louis Theran   \n",
       "2                                        Hongjun Pan   \n",
       "3                                       David Callan   \n",
       "4           Wael Abu-Shammala and Alberto Torchinsky   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "2  The evolution of the Earth-Moon system based o...   \n",
       "3  A determinant of Stirling cycle numbers counts...   \n",
       "4  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                                  comments  \\\n",
       "0  37 pages, 15 figures; published version   \n",
       "1    To appear in Graphs and Combinatorics   \n",
       "2                      23 pages, 3 figures   \n",
       "3                                 11 pages   \n",
       "4                                     None   \n",
       "\n",
       "                                 journal-ref                         doi  \\\n",
       "0                   Phys.Rev.D76:013009,2007  10.1103/PhysRevD.76.013009   \n",
       "1                                       None                        None   \n",
       "2                                       None                        None   \n",
       "3                                       None                        None   \n",
       "4  Illinois J. Math. 52 (2008) no.2, 681-689                        None   \n",
       "\n",
       "          report-no       categories  \\\n",
       "0  ANL-HEP-PR-07-12           hep-ph   \n",
       "1              None    math.CO cs.CG   \n",
       "2              None   physics.gen-ph   \n",
       "3              None          math.CO   \n",
       "4              None  math.CA math.FA   \n",
       "\n",
       "                                             license  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2    The evolution of Earth-Moon system is descri...   \n",
       "3    We show that a determinant of Stirling cycle...   \n",
       "4    In this paper we show how to compute the $\\L...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "2  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2008-01-13   \n",
       "3  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2007-05-23   \n",
       "4  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2013-10-15   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0  [[Bal√°zs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
       "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  \n",
       "2                                 [[Pan, Hongjun, ]]  \n",
       "3                                [[Callan, David, ]]  \n",
       "4  [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "def load_file():\n",
    "    with open('./data/arxiv-metadata-oai-snapshot.json') as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "\n",
    "metadata = load_file()\n",
    "\n",
    "subset = itertools.islice(metadata, 100000)\n",
    "\n",
    "df = pd.DataFrame(subset)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c365ff8",
   "metadata": {},
   "source": [
    "Similar to what we did for the \"bow_model.ipynb\" notebook, we are only looking into the 6 major categories for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34912c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df[df['categories'].isin(['hep-ph', 'quant-ph', 'astro-ph', 'hep-th', 'gr-qc', 'cond-mat.mtrl-sci'])] # high energy physics/quantum physics\n",
    "df_cat['categories'].value_counts()\n",
    "\n",
    "df_cat = pd.get_dummies(df_cat, columns=['categories'])\n",
    "\n",
    "X = df_cat['abstract']\n",
    "\n",
    "# Dependent Variables\n",
    "y = df_cat[['categories_astro-ph', 'categories_gr-qc',\n",
    "            'categories_hep-ph', 'categories_hep-th', 'categories_quant-ph', 'categories_cond-mat.mtrl-sci']]\n",
    "\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dbaf23",
   "metadata": {},
   "source": [
    "## 3. Text preprocessing\n",
    "\n",
    "1. We first initialize the tokenizer to split the words into lists of tokens. The num_words is set to 20000, which is the maximum number to keep.\n",
    "2. Using 'fit_on_texts' function to update the internal vocabulary based on the list of texts. \n",
    "3. Calling the 'texts_to_sequences' function which transforms each text in texts to a sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da50332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of word Index: 46580\n",
      "First 5 elements in the word_index dictionary: {'the': 1, 'of': 2, 'and': 3, 'a': 4, 'in': 5}\n",
      "First abstract text in training set:\n",
      " [7, 885, 72, 2792, 183, 1, 1338, 1921, 4509, 602, 13, 3816, 916, 39, 408, 1, 1013, 541, 1339, 496, 4195, 1932, 950, 39, 9, 1, 2215, 123, 3722, 91, 2, 1542, 176, 974, 4, 3, 64, 135, 17, 85, 17, 2617, 1719, 7, 682, 1013, 100, 255, 1104, 1961, 404, 2, 4346, 649, 3, 43, 25, 55, 341, 179, 180, 39, 16, 1, 219, 53, 2, 1, 1463, 1104, 653, 2829, 6, 1714, 5, 30, 2670, 7, 885, 1, 2, 1, 3722, 1815, 4, 64, 3, 4, 22, 1434, 5, 916, 3, 496, 4195, 39, 18, 90, 650, 3, 2041, 1, 4594, 3, 2378, 182, 7, 36, 473, 1, 515, 46, 82, 182, 3, 1, 271, 46, 82, 182, 77, 17, 4, 118, 2, 194, 42, 916, 3, 950, 141, 565, 13, 3722]\n"
     ]
    }
   ],
   "source": [
    "# Initializing the class\n",
    "tokenizer = Tokenizer(num_words = MAX_NUM_WORDS)\n",
    "# Updates internal vocabulary based on a list of texts.\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Length of word Index:\", len(word_index))\n",
    "print(\"First 5 elements in the word_index dictionary:\", dict(list(word_index.items())[0: 5]) )\n",
    "print(\"First abstract text in training set:\\n\", train_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed119380",
   "metadata": {},
   "source": [
    "Now that we have tokenized the comment texts, we need to pad the sentences to make all the sentences of equal length. This is because for DL model inputs, we should have a fixed length of data inputs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9895ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded sequence list:\n",
      " (23494, 1000)\n",
      "First abstract text in training set - 0 for padding - only last 50 sequences as the rest are paddings:\n",
      " [   4   64    3    4   22 1434    5  916    3  496 4195   39   18   90\n",
      "  650    3 2041    1 4594    3 2378  182    7   36  473    1  515   46\n",
      "   82  182    3    1  271   46   82  182   77   17    4  118    2  194\n",
      "   42  916    3  950  141  565   13 3722]\n"
     ]
    }
   ],
   "source": [
    "# Pad tokenized sequences\n",
    "trainvalid_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(\"Shape of padded sequence list:\\n\", trainvalid_data.shape)\n",
    "print(\"First abstract text in training set - 0 for padding - only last 50 sequences as the rest are paddings:\\n\", trainvalid_data[0][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607ecd3",
   "metadata": {},
   "source": [
    "## 4. Data modeling\n",
    "\n",
    "LSTM model is used as the classifier model. It is a special kind of RNN, capable of learning long-term dependencies. All RNNs have the form of a chain of repeating modules of neural network. LSTMs also have this chain like structure, but instead of the hidden layer we have something called LSTM cell and we have another connection that runs through all the time steps along with the hidden state. This is the called the \"Cell State\" vector from which information can be retrieved and removed as and when required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49fb39cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         640000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 772,358\n",
      "Trainable params: 772,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, LSTM, Embedding, Input\n",
    "\n",
    "# Using LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(MAX_NUM_WORDS, 128))\n",
    "lstm_model.add(LSTM(units = 128, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "lstm_model.add(Dense(units = 6, activation = 'sigmoid'))\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6797f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17620, 1000) (17620, 6) (5874, 1000) (5874, 6)\n",
      "Epoch 1/3\n",
      "138/138 [==============================] - 5140s 37s/step - loss: 0.3671 - auc: 0.7874 - accuracy: 0.5230 - val_loss: 0.2617 - val_auc: 0.9033 - val_accuracy: 0.6549\n",
      "Epoch 2/3\n",
      "138/138 [==============================] - 7701s 56s/step - loss: 0.2371 - auc: 0.9166 - accuracy: 0.6905 - val_loss: 0.1949 - val_auc: 0.9469 - val_accuracy: 0.7601\n",
      "Epoch 3/3\n",
      "138/138 [==============================] - 8320s 60s/step - loss: 0.1646 - auc: 0.9620 - accuracy: 0.7934 - val_loss: 0.1426 - val_auc: 0.9715 - val_accuracy: 0.8337\n"
     ]
    }
   ],
   "source": [
    "# Configures the model for training.\n",
    "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"AUC\", \"accuracy\"])\n",
    "\n",
    "# Split the dataset into train and validation set for training and evaludating the model\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainvalid_data, train_labels, shuffle=True, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "# Trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "history = rnn_model.fit(X_train, y_train, batch_size=128, epochs=3, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d415dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      4990\n",
      "           1       0.01      0.50      0.01         8\n",
      "           2       0.90      0.88      0.89      1645\n",
      "           3       0.71      0.71      0.71      1111\n",
      "           4       0.96      0.60      0.74      1990\n",
      "           5       0.26      0.52      0.35       326\n",
      "\n",
      "    accuracy                           0.83     10070\n",
      "   macro avg       0.64      0.69      0.61     10070\n",
      "weighted avg       0.91      0.83      0.86     10070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the CNN model to output probabilities on test data\n",
    "y_preds = rnn_model.predict(test_data)\n",
    "\n",
    "y_vals = test_labels.to_numpy()\n",
    "# Model Probabilities for class 1 of each of the target variables\n",
    "# y_preds = np.transpose(np.array(cnn_model.predict_proba(X_val))[:, :, 1])\n",
    "\n",
    "y_preds_2 = np.argmax(y_preds, axis=1)\n",
    "y_test_2 = np.argmax(y_vals, axis=1)\n",
    "print(f\"The Classification report: \\n\")\n",
    "print(classification_report(y_preds_2, y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35efb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc(y_test, y_pred):\n",
    "    aucs = []\n",
    "    # Calculate the ROC-AUC for each of the target column\n",
    "    for col in range(y_test.shape[1]):\n",
    "        aucs.append(roc_auc_score(y_test[:,col],y_pred[:,col]))\n",
    "    return aucs\n",
    "\n",
    "# Calculate Mean of the ROC-AUC\n",
    "mean_auc = mean(calculate_roc_auc(y_vals, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce80ddde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949598733076606"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933a130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_gpu]",
   "language": "python",
   "name": "conda-env-python_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
